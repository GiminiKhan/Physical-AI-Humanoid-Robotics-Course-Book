"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[421],{8929:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"1. Introduction to Physical AI","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Course-Book/docs/introduction-to-physical-ai/intro","label":"Introduction to Physical AI: Embodied Intelligence","docId":"introduction-to-physical-ai/intro","unlisted":false}]},{"type":"category","label":"2. ROS 2 Fundamentals","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Course-Book/docs/ros-2-fundamentals/intro","label":"ROS 2 Fundamentals: Building the Robot\'s Central Nervous System","docId":"ros-2-fundamentals/intro","unlisted":false}]},{"type":"category","label":"3. Robot Simulation (Digital Twin)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Course-Book/docs/robot-simulation/intro","label":"Robot Simulation (Digital Twin): Gazebo and Beyond","docId":"robot-simulation/intro","unlisted":false}]},{"type":"category","label":"4. The AI-Robot Brain (NVIDIA Isaac)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Course-Book/docs/the-ai-robot-brain/intro","label":"The AI-Robot Brain (NVIDIA Isaac): Simulation, Perception, and Navigation","docId":"the-ai-robot-brain/intro","unlisted":false}]},{"type":"category","label":"5. Humanoid Robot Development","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Course-Book/docs/humanoid-robot-development/intro","label":"Humanoid Robot Development: Kinematics, Dynamics, and Control","docId":"humanoid-robot-development/intro","unlisted":false}]},{"type":"category","label":"6. Conversational Robotics (VLA)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics-Course-Book/docs/conversational-robotics/intro","label":"Conversational Robotics (VLA): Vision-Language-Action Models","docId":"conversational-robotics/intro","unlisted":false}]}]},"docs":{"conversational-robotics/intro":{"id":"conversational-robotics/intro","title":"Conversational Robotics (VLA): Vision-Language-Action Models","description":"Conversational Robotics, leveraging Vision-Language-Action (VLA) models, represents the pinnacle of Physical AI, aiming to create robots that can understand, reason, and act in the physical world based on natural language commands and visual perception. This integration allows humanoids to go beyond pre-programmed tasks, enabling intuitive human-robot interaction and adaptive behavior in complex, unstructured environments. The pipeline typically involves processing human speech, translating it into abstract goals, converting these goals into concrete robot actions, and executing them while continuously perceiving the environment.","sidebar":"tutorialSidebar"},"humanoid-robot-development/intro":{"id":"humanoid-robot-development/intro","title":"Humanoid Robot Development: Kinematics, Dynamics, and Control","description":"Humanoid robots represent one of the most challenging and exciting frontiers in robotics. Mimicking human form and motion introduces extraordinary complexity, primarily due to the high number of degrees of freedom (DoF), the intricate balance requirements for bipedal locomotion, and the need for dynamic stability. Developing such robots demands a deep understanding of kinematics (the study of motion without considering forces), dynamics (the study of motion considering forces), and sophisticated control strategies.","sidebar":"tutorialSidebar"},"introduction-to-physical-ai/intro":{"id":"introduction-to-physical-ai/intro","title":"Introduction to Physical AI: Embodied Intelligence","description":"Physical AI represents a paradigm shift from purely digital artificial intelligence to systems that interact with and perceive the real world through physical embodiment. Unlike traditional AI that operates within virtual environments, Physical AI integrates robotics, sensors, and actuators to perform tasks in dynamic, unpredictable physical spaces. This fusion brings AI out of the cloud and into tangible forms, enabling robots to learn, adapt, and make decisions based on real-time sensory input. The core challenge lies in bridging the gap between theoretical AI models and their practical application in physical systems, where factors like latency, sensor noise, and mechanical limitations become critical.","sidebar":"tutorialSidebar"},"robot-simulation/intro":{"id":"robot-simulation/intro","title":"Robot Simulation (Digital Twin): Gazebo and Beyond","description":"Robot simulation is a cornerstone of modern robotics development, offering a safe, cost-effective, and efficient environment for testing algorithms, designing robots, and even training AI models. The concept of a \\"digital twin\\" is particularly powerful here: a virtual replica of a physical robot and its environment, allowing for realistic experimentation without the risks and expenses associated with real hardware. Gazebo is one of the most widely used robot simulators in the ROS ecosystem, providing a robust physics engine and a rich set of tools for creating complex scenarios.","sidebar":"tutorialSidebar"},"ros-2-fundamentals/intro":{"id":"ros-2-fundamentals/intro","title":"ROS 2 Fundamentals: Building the Robot\'s Central Nervous System","description":"The Robot Operating System (ROS) is not an operating system in the traditional sense, but rather a flexible framework for writing robot software. It\'s a collection of tools, libraries, and conventions that simplify the complex task of creating sophisticated robot applications. ROS 2 is the latest iteration, re-engineered to address modern robotics challenges such as multi-robot systems, real-time control, and embedded platforms like the NVIDIA Jetson Orin Nano. At its core, ROS 2 provides a standardized communication infrastructure that allows different components of a robot (e.g., sensors, actuators, navigation algorithms, UI) to communicate seamlessly, forming what can be thought of as the robot\'s central nervous system.","sidebar":"tutorialSidebar"},"the-ai-robot-brain/intro":{"id":"the-ai-robot-brain/intro","title":"The AI-Robot Brain (NVIDIA Isaac): Simulation, Perception, and Navigation","description":"NVIDIA Isaac is a comprehensive platform designed to accelerate the development and deployment of AI-powered robots. It encompasses tools for simulation, perception, and navigation, tightly integrated to facilitate the entire robot development lifecycle. At its core lies Isaac Sim, a powerful robotics simulator built on NVIDIA Omniverse, which provides photorealistic rendering and physically accurate environments crucial for training and testing complex Physical AI systems.","sidebar":"tutorialSidebar"}}}}')}}]);